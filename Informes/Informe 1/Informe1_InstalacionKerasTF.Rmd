---
title: "Informe 1: Prueba Deep Learning desde R"
author: "Carmen Lebrero Cia"
date: "28/9/2020"
output:
  pdf_document: 
    toc: yes
  html_document:
    df_print: paged
    toc: true
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Para la implementación de la metodología de Deep learning se puede trabajar con R o python. En cualquier caso, utilizar las librerías keras para deep learning (https://keras.io/ , https://blog.rstudio.com/2017/09/05/keras-for-r/, https://www.datacamp.com/community/tutorials/keras-r-deep-learning )

* Tambíén se puede usar tensorflow directamente

Una distribución de Python muy amigable es “**Anaconda**”
(https://www.anaconda.com/ ,
https://en.wikipedia.org/wiki/Anaconda_(Python_distribution)).

# Installation

To begin, install the keras R package from CRAN as follows:

```{r, eval=F, echo=T}
install.packages("keras")
```

The Keras R interface uses the TensorFlow backend engine by default. To install both the core Keras library as well as the TensorFlow backend use the install_keras() function:

```{r}
library(keras)
install_keras()
```

# MNIST Example

We can learn the basics of Keras by walking through a simple example: recognizing handwritten digits from the MNIST dataset. MNIST consists of 28 x 28 grayscale images of handwritten digits. The dataset also includes labels for each image, telling us which digit it is. For example, the labels for the above images are 5, 0, 4, and 1.

## Preparing the Data

The MNIST dataset is included with Keras and can be accessed using the dataset_mnist() function. Here we load the dataset then create variables for our test and training data:

```{r}
library(keras)
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
```

The **x data** is a 3-d array (images,width,height) of grayscale values. To prepare the data for training we convert the 3-d arrays into matrices by reshaping width and height into a single dimension (28x28 images are flattened into length 784 vectors). Then, we convert the grayscale values from integers ranging between 0 to 255 into floating point values ranging between 0 and 1:

```{r}
# reshape
dim(x_train) <- c(nrow(x_train), 784)
dim(x_test) <- c(nrow(x_test), 784)
# rescale
x_train <- x_train / 255
x_test <- x_test / 255
```

  

```{r}
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
```

## Defining the model

The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the sequential model, a linear stack of layers.

We begin by creating a sequential model and then adding layers using the pipe (%>%) operator:

```{r}
model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 256, activation = "relu", input_shape = c(784)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 10, activation = "softmax")
```

The input_shape argument to the first layer specifies the shape of the input data (a length 784 numeric vector representing a grayscale image). The final layer outputs a length 10 numeric vector (probabilities for each digit) using a softmax activation function.

Use the summary() function to print the details of the model:

```{r}
summary(model)
```

Next, compile the model with appropriate loss function, optimizer, and metrics:

```{r}
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(),
  metrics = c("accuracy")
)
```

## Training and Evaluation

Use the fit() function to train the model for 30 epochs using batches of 128 images:

```{r}
history <- model %>% fit(
  x_train, y_train, 
  epochs = 30, batch_size = 128, 
  validation_split = 0.2
)
```

The history object returned by fit() includes loss and accuracy metrics which we can plot:

```{r}
plot(history)
```

Evaluate the model’s performance on the test data:

```{r}
model %>% evaluate(x_test, y_test,verbose = 0)
```

Generate predictions on new data:

```{r}
model %>% predict_classes(x_test)
```

Keras provides a vocabulary for building deep learning models that is simple, elegant, and intuitive. Building a question answering system, an image classification model, a neural Turing machine, or any other model is just as straightforward.

The Guide to the Sequential Model article describes the basics of Keras sequential models in more depth.

